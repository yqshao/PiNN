
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.13">
    
    
      
        <title>PiNet - PiNN Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e411adfe.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cc9b2e1e.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#the-pinet-network" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">
          
        </aside>
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="PiNN Documentation" class="md-header__button md-logo" aria-label="PiNN Documentation" data-md-component="logo">
      
  <img src="../../images/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PiNN Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              PiNet
            
          </span>
        </div>
      </div>
    </div>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="PiNN Documentation" class="md-nav__button md-logo" aria-label="PiNN Documentation" data-md-component="logo">
      
  <img src="../../images/logo.svg" alt="logo">

    </a>
    PiNN Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Home" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Home
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../migration/" class="md-nav__link">
        Migration to PiNN 1.x
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../changelog/" class="md-nav__link">
        Changelog
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Usage
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Usage" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Usage
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../quick_start/" class="md-nav__link">
        Quick Start
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_3">
          CLI
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="CLI" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          CLI
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cli/convert/" class="md-nav__link">
        convert
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cli/train/" class="md-nav__link">
        train
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../cli/log/" class="md-nav__link">
        log
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../datasets/" class="md-nav__link">
        Datasets
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_5" type="checkbox" id="__nav_2_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2_5">
          Networks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Networks" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_5">
          <span class="md-nav__icon md-icon"></span>
          Networks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../networks/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          PiNet
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        PiNet
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#network-architecture" class="md-nav__link">
    Network architecture
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#network-parameters" class="md-nav__link">
    Network parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layer-specifications" class="md-nav__link">
    Layer specifications
  </a>
  
    <nav class="md-nav" aria-label="Layer specifications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pinetfflayer-pp-and-ii" class="md-nav__link">
    pinet.FFLayer (PP and II)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetpilayer" class="md-nav__link">
    pinet.PILayer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetiplayer" class="md-nav__link">
    pinet.IPLayer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetresupdate" class="md-nav__link">
    pinet.ResUpdate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetoutlayer" class="md-nav__link">
    pinet.OutLayer
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bpnn/" class="md-nav__link">
        BPNN
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_6" type="checkbox" id="__nav_2_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_6">
          Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Models" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_6">
          <span class="md-nav__icon md-icon"></span>
          Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../potential/" class="md-nav__link">
        Potential Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dipole/" class="md-nav__link">
        Dipole Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../custom_model/" class="md-nav__link">
        Custom Mdoel
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/" class="md-nav__link">
        Optimizers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../visualize/" class="md-nav__link">
        Visualize
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Notebooks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Notebooks" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Notebooks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/overview/" class="md-nav__link">
        Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_2">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/Quick_tour/" class="md-nav__link">
        Quick tour with QM9
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/More_on_training/" class="md-nav__link">
        Optimizing the training
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_3">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Examples" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/Customizing_dataset/" class="md-nav__link">
        Customizing dataset
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../notebooks/Learn_LJ_potential/" class="md-nav__link">
        Learning a LJ potential
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#network-architecture" class="md-nav__link">
    Network architecture
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#network-parameters" class="md-nav__link">
    Network parameters
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layer-specifications" class="md-nav__link">
    Layer specifications
  </a>
  
    <nav class="md-nav" aria-label="Layer specifications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pinetfflayer-pp-and-ii" class="md-nav__link">
    pinet.FFLayer (PP and II)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetpilayer" class="md-nav__link">
    pinet.PILayer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetiplayer" class="md-nav__link">
    pinet.IPLayer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetresupdate" class="md-nav__link">
    pinet.ResUpdate
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pinetoutlayer" class="md-nav__link">
    pinet.OutLayer
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


<h1 id="the-pinet-network">The PiNet network</h1>
<p>The PiNet network implements the network architecture described in our
paper.<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> The network architecture features the
graph-convolution which recursively generates atomic properties from local
environment.</p>
<p>One distinctive feature of PiNet is that the convolution operation is realized
with pairwise functions whose form are determined by the pair, called pairwise
interactions.</p>
<h2 id="network-architecture">Network architecture</h2>
<p>The overall architecture of PiNet is illustrated with the graph convolution block below:</p>
<p><img alt="PiNet architecture" src="../../tikz/pinet.svg" width="600" /></p>
<p>We classify the latent variables into the atom-centered "properties"
(<span class="arithmatex"><span class="MathJax_Preview">\mathbb{P}</span><script type="math/tex">\mathbb{P}</script></span>) and the pair-wise "interactions" (<span class="arithmatex"><span class="MathJax_Preview">\mathbb{I}</span><script type="math/tex">\mathbb{I}</script></span>) in our notation.
Since the layers that transform <span class="arithmatex"><span class="MathJax_Preview">\mathbb{P}\to\mathbb{P}</span><script type="math/tex">\mathbb{P}\to\mathbb{P}</script></span> or
<span class="arithmatex"><span class="MathJax_Preview">\mathbb{I}\to\mathbb{I}</span><script type="math/tex">\mathbb{I}\to\mathbb{I}</script></span> are usually standard feed-forward neural networks (FF
layers), the more important part of PiNet are the PI and IP layers, which
transform between those two types of variables.</p>
<p>The operations are generally grouped into the PI and IP operations that
constitutes a GC block, which can be further composed of individual layers, as
shown above. Each of the layers is sub-classed from <code>tf.keras.layers.Layer</code>. The
<code>PiNet</code> class provides a few parameters to control those layers. Check the layer
specification below for more detailed description of the layers.</p>
<h2 id="network-parameters">Network parameters</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>atom_types</td>
<td><code>[1, 6, 7, 8]</code></td>
<td>List of elements</td>
</tr>
<tr>
<td>rc</td>
<td><code>4.0</code></td>
<td>Cutoff radius</td>
</tr>
<tr>
<td>cutoff_type</td>
<td><code>'f1'</code></td>
<td>One of 'f1' or 'f2'</td>
</tr>
<tr>
<td>basis_type</td>
<td><code>'polynomial'</code></td>
<td>One of 'polynomial' or 'gaussian'</td>
</tr>
<tr>
<td>n_basis</td>
<td><code>4</code></td>
<td>Number of radial basis functions to generate</td>
</tr>
<tr>
<td>gamma</td>
<td><code>3.0</code></td>
<td>controls width of the Gaussian basis</td>
</tr>
<tr>
<td>center</td>
<td><code>None</code></td>
<td>replace centers the for Gaussian basis with a list</td>
</tr>
<tr>
<td>pp_nodes</td>
<td><code>[16, 16]</code></td>
<td>specifies the property-property hidden layers</td>
</tr>
<tr>
<td>pi_nodes</td>
<td><code>[16, 16]</code></td>
<td>specifies the property-interaction hidden layers</td>
</tr>
<tr>
<td>ii_nodes</td>
<td><code>[16, 16]</code></td>
<td>specifies the interaction-interaction hidden layers</td>
</tr>
<tr>
<td>out_nodes</td>
<td><code>[16, 16]</code></td>
<td>specifies the output hidden layers</td>
</tr>
<tr>
<td>out_units</td>
<td><code>1</code></td>
<td>the dimension of outputs</td>
</tr>
<tr>
<td>out_pool</td>
<td><code>False</code></td>
<td><code>min</code>, <code>max</code> or <code>sum</code>, pool atomic outputs to give global predictions</td>
</tr>
<tr>
<td>act</td>
<td><code>'tanh'</code></td>
<td>activation function to use</td>
</tr>
<tr>
<td>depth</td>
<td><code>4</code></td>
<td>number of graph-convolution layers to use</td>
</tr>
</tbody>
</table>
<h2 id="layer-specifications">Layer specifications</h2>
<h3 id="pinetfflayer-pp-and-ii">pinet.FFLayer (PP and II)</h3>


  <div class="doc doc-object doc-class">


    <div class="doc doc-contents first">

      <p>The FFLayer is a shortcut to create a multi-layer perceptron (MLP) or a
feed-forward network. A FFLayer takes one tensor as input of arbitratry
shape, and outputs a tensor with shape <code>[..., n_nodes[-1]]</code> The keyward
arguments are parsed into the <code>tf.keras.layers.Dense</code> class, which can be
used to specify the bias, activation function, etc.</p>
<p><code>PPLayer</code> and <code>IILayer</code> in the architecture are instances of the <code>FFLayer</code>
class, with the difference that <code>IILayer</code>s have their baises set to zero to
avoid discontinuity in the model output.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>n_node</code></td>
        <td><p>dimension of the layers</p></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td><p>keyword arguments</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>pinn/networks/pinet.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">FFLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The FFLayer is a shortcut to create a multi-layer perceptron (MLP) or a</span>
<span class="sd">    feed-forward network. A FFLayer takes one tensor as input of arbitratry</span>
<span class="sd">    shape, and outputs a tensor with shape `[..., n_nodes[-1]]` The keyward</span>
<span class="sd">    arguments are parsed into the `tf.keras.layers.Dense` class, which can be</span>
<span class="sd">    used to specify the bias, activation function, etc.</span>

<span class="sd">    `PPLayer` and `IILayer` in the architecture are instances of the `FFLayer`</span>
<span class="sd">    class, with the difference that `IILayer`s have their baises set to zero to</span>
<span class="sd">    avoid discontinuity in the model output.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_node (list): dimension of the layers</span>
<span class="sd">        **kwargs: keyword arguments</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_nodes</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FFLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="n">n_node</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">n_node</span> <span class="ow">in</span> <span class="n">n_nodes</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">













  </div>

    </div>

  </div>

<h3 id="pinetpilayer">pinet.PILayer</h3>


  <div class="doc doc-object doc-class">


    <div class="doc doc-contents first">

      <p>The PILayer takes the properties (<span class="arithmatex"><span class="MathJax_Preview">\mathbb{P}_{i}, \mathbb{P}_{j}</span><script type="math/tex">\mathbb{P}_{i}, \mathbb{P}_{j}</script></span>) of a
pair of atoms as input and outputs a set of interactions for each pair. The
input <span class="arithmatex"><span class="MathJax_Preview">\mathbb{P}_{i}, \mathbb{P}_{j}</span><script type="math/tex">\mathbb{P}_{i}, \mathbb{P}_{j}</script></span> will be concatenated as the input of
a feed-forward neural network (FFLayer), and the interactions are generated
by taking the output of the FFLayer as weights of radial basis functions,
i.e.:</p>
<div class="arithmatex">
<div class="MathJax_Preview">
\begin{aligned}
W_{ijb} &amp;= \mathrm{NN}^{\mathrm{PI}}(\mathbb{P}_{i}\Vert\mathbb{P}_{j}) \\
\mathbb{I}_{ij} &amp;= \sum_b W_{ijb} \cdot e_{ijb}
\end{aligned}
</div>
<script type="math/tex; mode=display">
\begin{aligned}
W_{ijb} &= \mathrm{NN}^{\mathrm{PI}}(\mathbb{P}_{i}\Vert\mathbb{P}_{j}) \\
\mathbb{I}_{ij} &= \sum_b W_{ijb} \cdot e_{ijb}
\end{aligned}
</script>
</div>
<p>The layer specified by the number of nodes to be used in the FFLayer
(n_nodes).</p>
<div class="admonition note">
<p>Note that the last element of n_nodes specifies the dimention of the
fully connected network before applying the basis function.
Dimension of the last node is <code>[pairs,n_nodes[-1]*n_basis]</code>, the
output is then summed with the basis to form the interaction nodes.</p>
</div>
<p>A PILayer takes a tuple of three tensors as input:</p>
<ul>
<li>ind_2: sparse indices of pairs with shape <code>(n_pairs, 2)</code></li>
<li>prop: property tensor with shape <code>(n_atoms, n_prop)</code></li>
<li>basis: radial basis functions with shape <code>(n_pairs, n_basis)</code></li>
</ul>
<p>, and returns an interaction tensor with shape <code>(n_atoms, n_inter)</code></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>n_nodes</code></td>
        <td><p>number of nodes to use</p></td>
      </tr>
      <tr>
        <td><code>**kwargs</code></td>
        <td><p>keyword arguments will be parsed to the feed forward layers</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>pinn/networks/pinet.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">PILayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The PILayer takes the properties ($\mathbb{P}_{i}, \mathbb{P}_{j}$) of a</span>
<span class="sd">    pair of atoms as input and outputs a set of interactions for each pair. The</span>
<span class="sd">    input $\mathbb{P}_{i}, \mathbb{P}_{j}$ will be concatenated as the input of</span>
<span class="sd">    a feed-forward neural network (FFLayer), and the interactions are generated</span>
<span class="sd">    by taking the output of the FFLayer as weights of radial basis functions,</span>
<span class="sd">    i.e.:</span>

<span class="sd">    $$</span>
<span class="sd">    \\begin{aligned}</span>
<span class="sd">    W_{ijb} &amp;= \mathrm{NN}^{\mathrm{PI}}(\mathbb{P}_{i}\Vert\mathbb{P}_{j}) \\\\</span>
<span class="sd">    \mathbb{I}_{ij} &amp;= \sum_b W_{ijb} \cdot e_{ijb}</span>
<span class="sd">    \end{aligned}</span>
<span class="sd">    $$</span>

<span class="sd">    The layer specified by the number of nodes to be used in the FFLayer</span>
<span class="sd">    (n_nodes).</span>

<span class="sd">    !!! note &quot;&quot;</span>
<span class="sd">        Note that the last element of n_nodes specifies the dimention of the</span>
<span class="sd">        fully connected network before applying the basis function.</span>
<span class="sd">        Dimension of the last node is `[pairs,n_nodes[-1]*n_basis]`, the</span>
<span class="sd">        output is then summed with the basis to form the interaction nodes.</span>

<span class="sd">    A PILayer takes a tuple of three tensors as input:</span>

<span class="sd">    - ind_2: sparse indices of pairs with shape `(n_pairs, 2)`</span>
<span class="sd">    - prop: property tensor with shape `(n_atoms, n_prop)`</span>
<span class="sd">    - basis: radial basis functions with shape `(n_pairs, n_basis)`</span>

<span class="sd">    , and returns an interaction tensor with shape `(n_atoms, n_inter)`</span>


<span class="sd">    Args:</span>
<span class="sd">        n_nodes: number of nodes to use</span>
<span class="sd">        **kwargs: keyword arguments will be parsed to the feed forward layers</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_nodes</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PILayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span> <span class="o">=</span> <span class="n">n_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shapes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_basis</span> <span class="o">=</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_nodes_iter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">n_nodes_iter</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_basis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_layer</span> <span class="o">=</span> <span class="n">FFLayer</span><span class="p">(</span><span class="n">n_nodes_iter</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="n">ind_2</span><span class="p">,</span> <span class="n">prop</span><span class="p">,</span> <span class="n">basis</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="n">ind_i</span> <span class="o">=</span> <span class="n">ind_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">ind_j</span> <span class="o">=</span> <span class="n">ind_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">prop_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="n">ind_i</span><span class="p">)</span>
        <span class="n">prop_j</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">prop</span><span class="p">,</span> <span class="n">ind_j</span><span class="p">)</span>

        <span class="n">inter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">prop_i</span><span class="p">,</span> <span class="n">prop_j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">inter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_layer</span><span class="p">(</span><span class="n">inter</span><span class="p">)</span>
        <span class="n">inter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inter</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_nodes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_basis</span><span class="p">])</span>
        <span class="n">inter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;pcb,pb-&gt;pc&#39;</span><span class="p">,</span> <span class="n">inter</span><span class="p">,</span> <span class="n">basis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inter</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">














  </div>

    </div>

  </div>

<h3 id="pinetiplayer">pinet.IPLayer</h3>


  <div class="doc doc-object doc-class">


    <div class="doc doc-contents first">

      <p>The IPLayer transforms pairwise interactions to atomic properties</p>
<p>An IPLayer takes a tuple of three tensors as input:</p>
<ul>
<li>ind_2: sparse indices of pairs with shape <code>(n_pairs, 2)</code></li>
<li>prop: property tensor with shape <code>(n_atoms, n_prop)</code></li>
<li>inter: interaction tensor with shape <code>(n_pairs, n_inter)</code></li>
</ul>
<p>, and returns a new property tensor with shape <code>(n_atoms, n_inter)</code>.</p>
<p>The IPLayer has no learnable variables and simply sums up the pairwise
interations. Thus the returned property has the same shape with the
input interaction.</p>

        <details class="quote">
          <summary>Source code in <code>pinn/networks/pinet.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">IPLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The IPLayer transforms pairwise interactions to atomic properties</span>

<span class="sd">        An IPLayer takes a tuple of three tensors as input:</span>

<span class="sd">        - ind_2: sparse indices of pairs with shape `(n_pairs, 2)`</span>
<span class="sd">        - prop: property tensor with shape `(n_atoms, n_prop)`</span>
<span class="sd">        - inter: interaction tensor with shape `(n_pairs, n_inter)`</span>

<span class="sd">        , and returns a new property tensor with shape `(n_atoms, n_inter)`.</span>

<span class="sd">        The IPLayer has no learnable variables and simply sums up the pairwise</span>
<span class="sd">        interations. Thus the returned property has the same shape with the</span>
<span class="sd">        input interaction.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">IPLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="n">ind_2</span><span class="p">,</span> <span class="n">prop</span><span class="p">,</span> <span class="n">inter</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="n">n_atoms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prop</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_sum</span><span class="p">(</span><span class="n">inter</span><span class="p">,</span> <span class="n">ind_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">n_atoms</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">













  </div>

    </div>

  </div>

<h3 id="pinetresupdate">pinet.ResUpdate</h3>


  <div class="doc doc-object doc-class">


    <div class="doc doc-contents first">

      <p>The ResUpdate layer implements ResNet-like update of properties that
addresses vanishing/exploding gradient problems (see
<a href="https://arxiv.org/abs/1512.03385">arXiv:1512.03385</a>).</p>
<p>It takes a tuple of two tensors (old and new) as input, the tensors should
have the same shape except for the last dimension, and a tensor with the
shape of the new tensor is always returned.</p>
<p>If shapes of the two tensors match, their sum is returned. If the two
tensors' shapes differ in the last dimension, the old tensor will be added
to the new after a learnable linear transformation that matches its shape to
the new tensor.</p>

        <details class="quote">
          <summary>Source code in <code>pinn/networks/pinet.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ResUpdate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The ResUpdate layer implements ResNet-like update of properties that</span>
<span class="sd">    addresses vanishing/exploding gradient problems (see</span>
<span class="sd">    [arXiv:1512.03385](https://arxiv.org/abs/1512.03385)).</span>

<span class="sd">    It takes a tuple of two tensors (old and new) as input, the tensors should</span>
<span class="sd">    have the same shape except for the last dimension, and a tensor with the</span>
<span class="sd">    shape of the new tensor is always returned.</span>

<span class="sd">    If shapes of the two tensors match, their sum is returned. If the two</span>
<span class="sd">    tensors&#39; shapes differ in the last dimension, the old tensor will be added</span>
<span class="sd">    to the new after a learnable linear transformation that matches its shape to</span>
<span class="sd">    the new tensor.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">ResUpdate</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shapes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shapes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapes</span><span class="p">)</span><span class="o">==</span><span class="mi">2</span>
        <span class="k">if</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
                <span class="n">shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="n">old</span><span class="p">,</span> <span class="n">new</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">old</span><span class="p">)</span> <span class="o">+</span> <span class="n">new</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">














  </div>

    </div>

  </div>

<h3 id="pinetoutlayer">pinet.OutLayer</h3>


  <div class="doc doc-object doc-class">


    <div class="doc doc-contents first">

      <p>The OutLayer is a simple combination of the FFLayer and the ResUpdate
layer, where the <code>out_units</code> controls the number of outputs to be updated.
In addition to the FFLayer, the OutLayer has one additional linear biasless
layer that scales the outputs.</p>
<p>An OutLayer takes a tuple of three tensors as input:</p>
<ul>
<li>ind_1: sparse indices of atoms with shape <code>(n_atoms, 2)</code></li>
<li>prop: property tensor with shape <code>(n_atoms, n_prop)</code></li>
<li>prev_output:  previous output with shape <code>(n_atoms, out_units)</code></li>
</ul>
<p>, and returns an updated output tensor with shape <code>(n_atoms, out_units)</code></p>

        <details class="quote">
          <summary>Source code in <code>pinn/networks/pinet.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">OutLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The OutLayer is a simple combination of the FFLayer and the ResUpdate</span>
<span class="sd">    layer, where the `out_units` controls the number of outputs to be updated.</span>
<span class="sd">    In addition to the FFLayer, the OutLayer has one additional linear biasless</span>
<span class="sd">    layer that scales the outputs.</span>

<span class="sd">    An OutLayer takes a tuple of three tensors as input:</span>

<span class="sd">    - ind_1: sparse indices of atoms with shape `(n_atoms, 2)`</span>
<span class="sd">    - prop: property tensor with shape `(n_atoms, n_prop)`</span>
<span class="sd">    - prev_output:  previous output with shape `(n_atoms, out_units)`</span>

<span class="sd">    , and returns an updated output tensor with shape `(n_atoms, out_units)`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">out_units</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OutLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_units</span> <span class="o">=</span> <span class="n">out_units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_layer</span> <span class="o">=</span> <span class="n">FFLayer</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_units</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
            <span class="n">out_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;&quot;&quot;&quot;</span>
        <span class="n">ind_1</span><span class="p">,</span> <span class="n">prop</span><span class="p">,</span> <span class="n">prev_output</span> <span class="o">=</span> <span class="n">tensors</span>
        <span class="n">prop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_layer</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_units</span><span class="p">(</span><span class="n">prop</span><span class="p">)</span> <span class="o">+</span> <span class="n">prev_output</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">













  </div>

    </div>

  </div>

<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Y. Shao, M. Hellström, P. D. Mitev, L. Knijff, and C. Zhang. PiNN: a python library for building atomic neural networks of molecules and materials. <em>J. Chem. Inf. Model.</em>, 60:1184–1193, January 2020. <a href="https://doi.org/10.1021/acs.jcim.9b00994">doi:10.1021/acs.jcim.9b00994</a>.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../networks/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Overview" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Overview
            </div>
          </div>
        </a>
      
      
        
        <a href="../bpnn/" class="md-footer__link md-footer__link--next" aria-label="Next: BPNN" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              BPNN
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections"], "search": "../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.ed9748b7.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>